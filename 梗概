1.	垃圾回收
2.	JVM 内存区域
虚拟机栈、本地方法栈、程序计数器、本地内存、堆
3.	如何识别垃圾
a)	引用计数法
不能解决循环引用
b)	可达性算法
GC Root 引用链，引用链外的是可回收对象
4.	垃圾回收主要方法
a)	标记清除法
问题：内存碎片
b)	复制法
解决内存碎片，但是空间减少一半，移动存活对象效率低下
c)	标记整理法
清除垃圾后需要频繁移动存活对象，效率低下
d)	分代收集算法
综合以上算法优点
新生代 ：老年代 1 : 2
		新生代 Eden : s0 : s1 8:1:1
		出现原因：98%的对象生命很短，一次Minor GC就会被回收、根据对象存活周期不同，出现分代收集算法
		新生代 Young GC（Minor GC）老年代 Old GC（Full GC）

		对象晋升到老年代：
1.	对象年龄达到阈值
2.	大对象
3.	s0或s1相同年龄对象大小之和大于s0或s1空间一半以上，年龄大于等于该年龄的对象
把新生代设置成 Eden, S0，S1区或者给对象设置年龄阈值或者默认把新生代与老年代的空间大小设置成 1:2 都是为了尽可能地避免对象过早地进入老年代，尽可能晚地触发 Full GC。
5.	垃圾回收器对比 
1.	在新生代工作的垃圾回收器：Serial, ParNew, ParallelScavenge
2.	在老年代工作的垃圾回收器：CMS，Serial Old, Parallel Old
3.	同时在新老生代工作的垃圾回收器：G1

Serial收集器：Serial 收集器是工作在新生代的，单线程的垃圾收集器
ParNew收集器：ParNew 收集器是 Serial 收集器的多线程版本，除了使用多线程，其
他像收集算法,STW,对象分配规则，回收策略与 Serial 收集器完成一样
CMS 收集器是以实现最短 STW 时间为目标的收集器，如果应用很重视服务的响应速度，希望给用户最好的体验，则 CMS 收集器是个很不错的选择！

2．Kafka
2.1 kafka基础
	天然分布式消息队列
	Producer –> Broker  Consumer
	生产者和消费者就得知道：把数据丢给哪个队列，从哪个队列消费消息。我们需要给队列取名字，叫做topic(相当于数据库里边表的概念)
为了提高一个队列(topic)的吞吐量，Kafka会把topic进行分区(Partition)
一台Kafka服务器叫做Broker，Kafka集群就是多台Kafka服务器
一个topic会分为多个partition，实际上partition会分布在不同的broker中
Kafka是天然分布式的。
高可用：
Kafka是这样做的：我们数据存在不同的partition上，那kafka就把这些partition做备份。比如，现在我们有三个partition，分别存在三台broker上。每个partition都会备份，这些备份散落在不同的broker上。
备份分区仅仅用作于备份，不做读写。如果某个Broker挂了，那就会选举出其他Broker的partition来作为主分区，这就实现了高可用。
3. RabbitMQ
基本架构


